% !TEX root = ../Thesis.tex
\chapter{Implementation}

In this section, we will introduce how we implemented a word-gesture keyboard using Unity and a python script and how we used SHARK2 for our algorithm.

\section*{Word Graph Generator}
As mentioned in the related-work SHARK2 part TODO: REFERENCE TO MENTIONED SECTION , to make SHARK2 work, the perfect graphs for all the words in a lexicon are needed. Therefore, we needed a script, that produces or overwrites a file for every available keyboard layout and writes the sampled points of every graph in it. Such a file contains per line a word, then a certain number of points from the word's perfect graph followed by the same points, but normalized (normalized as mentioned in the related-work SHARK2 section) TODO: REFERENCE TO MENTIONED SECTION.\\
To run the script, the user has to provide the name of the layout that he/she wants to create the perfect graphs for. Additionally, he/she has also to write the name of the text file containing all the words (lexicon). The script then either creates a new file named "sokgraph\_\textit{layout}.txt" or if already a file with this name exists, it deletes its content to write new in it. Then it fills the file line by line as mentioned above.\\
The file can only be executed for one layout a time. Hence, if there are more available layouts for our word-gesture keyboard, the user has to run the script several times.

\section{Used Algorithm}
For our word-gesture keyboard we used a weaker version of SHARK2. This means, we do also work with two channels, a location channel and a shape channel. The shape channel is to calculate the deviation from the user inputted graph and a perfect graph from a word in the sense of distance with respect to their shape, the location channel is for the same thing, but not for the shape, but rather the position. When looking at the shape, we have to normalize the graphs in a specific way, so the position, where they exactly lie in a coordinate system does not matter. When looking at the position, we look at the graphs as they are, without normalizing or changing anything. As in the SHARK2 system we also use the start and end positions of the graphs as pruning method. The difference is, that for SHARK2, the authors chose to use normalize all the graphs in scale and translation before comparing. We do not normalize the graphs, but just look at the start and end positions of a user input graph and a word's graph. Another thing we have almost implemented the same as it is in SHARK2 is $\delta$. For the shape and location channel integration, the used $\delta$ in SHARK2 is equal to the radius of one key. We do the same for the location channel (in the integration part), but we do not use the same $\delta$ for the shape channel (in the integration part). For this, we take a $\delta$ that equals the radius of a normalized key. That means, a small graph will have a bigger delta than a big graph, because we do normalize the graphs and a small graph gets stretched by it, whereby a big graph gets drawn together. TODO: REVISE.\\
However, we do currently not use any language information nor dynamic channel weighting by gesturing speed.

\section{Functions}
The most important, but also most basic function our word-gesture keyboard provides, is the writing of words with gestures. A user can press the trigger button of a VR controller inside the keyboards hitbox and start making a gesture on it. The user will see a TODO: SEE COLOR. red/purple line that is drawn on the keyboard where he/she moves. This helps the user to keep track of the trace he/she drew. When the user wants to finish the gesture, he/she needs to release the trigger of the controller. At this moment, our program starts to evaluate the 5 words with the highest accordance to the user inputted graph. The one with the highest accordance will be written into the text field. The other 4 are displayed at the keyboard TODO: CITE TO PICTURE WITH RECOMMENDATIONS., such that the user also can choose between these. When the user chooses one of these 4 words, the word that has been written into the text field before is getting replaced by the user's chosen word and the key, where the chosen word was written will then display the replaced word.\\
Because the whole system works with a lexicon full of words and only these can be written as gestures, there will also be word, the user wants to write, that are not yet in said lexicon. For this case, we implemented a function such that the user can add new words. He/She can access via an options button marked with a black gear right above the keyboard the "add word" button. When this button is pressed another button appears, the "add word to dict" button TODO: REVISE. When this button is pressed, the word (it does not need to be one, that really exists) displayed above the keyboard, will be added to the lexicon text file. Additionally for every availbable layout, the corresponding graph for the newly added word will be added to the corresponding "sokgraph\_\textit{layout}.txt" text file. One additonal thing we implemented is, that the word's graph only gets appended in the text file, if this word can be written with the layout the file corresponds to. For example, if a user wants to add the word "öffentlich", but he/she made a layout without the letter "ö", this word could never be written with said layout, hence it would be unnecessary to have this word in said "sokgraph\_textit{layout}.txt" text file.\\
Another function that is necessary for the previous function is the possibility to input single letters. If a word does not yet exist in the lexicon or layout text file, then it cannot be written with a gesture. Hence, we needed a way to input single letters. Fortunately with a word-gesture keyboard this almost works without additional work. If the single letters are as graphs in the layout files, TODO: DEFINE LEAYOUT FILES AS SOKRAPH_LAYOUT.TXT SOMEWHERE. the user is more or less able to write single letter with a gesture (just a click on the right key). But there might be a little inconvenience. This is caused by the fact, that we work with distances. The distance from one letter to another is not too big. And if for example the user wants to write an "e" but presses the key with the "e" on it on its left side and not perfectly in the middle, our system would also evaluate that aside from "e", also "w" and "we" are words, the user might have intended to write (on a conventional qwertz or qwerty layout). To get rid of this, our system checks, if the user inputted graph's bounded box is smaller than TODO: HOW MUCH SMALLER?. it recognizes, that the user wants to write a single letter, and then takes the best match. To get back to the example, "we" would be discarded and "e" would get a higher score than "w", because of a smaller location channel distance. Therefore the written "word" in this case would be "e".\\
Another function to help the user is the creation of own layouts. A layout text file exists, that contains all available layouts. The user can as many new layouts as he/she wants to. To create a new one, the user has to give the layout he/she wants to create a name and on the following lines write the characters in an order, that he/she wants to have on the keyboard. All the unicode characters should be working, but two. In the current implementation, one whitespace is used to declare the position of the spacebar and the "<" character is used for the backspace key. This file gets read at the start of the program, so it cannot be edited while the program is running, or to be precise, the changes will not be recognized during runtime. One smaller thing we implemented is, that at the start of the program TODO: START OF PROGRAM OR MORE LIKE APPERANCE OF KEYBOARD?. all characters used in the layout not yet in the lexicon text file and "sokgraph\_\textit{layout}.txt" are being added. Without doing this, the user may not be able to input any single special character with his/her newly created keyboard, because the system simply does not find it in the layout files. The user is during the runtim able to switch between available layouts whenever he/she wants to.\\
To end the implementation part, we will talk shortly about two small functions. One is, that the keyboard is grabable. This means, the user can grab the keyboard and move it around in the room. We were able to do this thanks to script taht already existed in vitrivr and did not have to implement anything on our own.\\
The last small function is the ability to change the size of the keyboard. This can help the user writing words, depending on how he/she wants to move his/her arm and therefore put the keyboard a bit closer or further away.



---"draw" words with gestures/put single letters
---create own layout
change size
---choose between best 5 words
keyboard is movable
---chose between available layouts all the time possible
---add new words
