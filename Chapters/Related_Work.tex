% !TEX root = ../Thesis.tex
\chapter{Related Work/ Background}

In this chapter we introduce the environment the word-gesture keyboard is mainly developed for, some things about the normal, conventional keyboard and word-gesture keyboard in general, with an excursion about SHARK2.

\section{vitrivr-VR and UnityVR}
vitrivr\footnote{https://vitrivr.org/} is an open source full stack content-based multimedia retrieval system. It supports image, audio and 3D collections and features a very broad set of query paradigms that are supported. vitrivr was developed by the Database and Information Systems group\footnote{https://dbis.dmi.unibas.ch} (dbis) of the university of Basel. For our thesis, we use the VR part of vitrivr, namely vitrivr-VR. This is being developed in Unity\footnote{https://unity.com}. Unity is a tool for developers, where one can create projects in 2D, 3D and VR. To a certain degree, Unity is free to use, but one can provide assets that are not for free. In Unity, a developer can also provide packages. These can be imported and used by other developers in their Unity projects.

\section{Conventional Keyboard}
A conventional keyboard is the most used keyboard type. On desktop and laptop computers we normally use such a keyboard. One thing that might be different in some countries is the layout. The layout does not change the functionality but can influence the appearance. This also applies to the most used keyboard for phones, tablets and other touchscreen-based devices. The only difference is that we do not press physical keys, but tap on the screen, where a certain key is. These keyboards work really well for text input with the previously mentioned devices. But when it comes to virtual reality (VR) or augmented reality (AR), this may not be the best possible text input method. Right now, it lacks of tactile feedback and accurate finger tracking. While this could be improved during the next years, yet it is not really there. Another reason is the size of such keyboards in VR. Due to the lack of accurate finger tracking, we have to tap on the keys with our controllers. If the keys are too close together, it might cause a problem in recognizing which key was pressed. Therefore, there needs to be either bigger keys or bigger spaces between two adjacent keys. This results in a bigger keyboard, which results in more needed movement with the arms. If we have to move our arms a lot to input some text, this can quickly become exhausting.

\section{Word-Gesture Keyboard}
A word-gesture keyboard may look pretty much the same as a conventional keyboard described in the last section, but works completely different. Independent of the details of the implementation, every word-gesture keyboard (also called slide-to-type keyboard) works with gestures. That means, instead of tapping on single keys, we have to draw one line or a shape on the keyboard. This will then be evaluated by an algorithm, that determines the closest word from a lexicon. Here closeness is determined by shape comparison between the user input and a word from the lexicon. 

\subsection{SHARK2}
SHARK2 is a "large vocabulary shorthand writing system for pen-based computers" \cite{Kristensson2004SHARK2AL} invented by Shumin Zhai and Per-Ola Kristensson. It can compare the user inputted graph with a perfect graph of any word. A perfect graph is the graph, that is produced, if we start from the center of the word's first letter on the keyboard. Then we draw a straight line to the center of the next letter of the word and so on, until we reach the last letter.\\
The SHARK2 system needs a lexicon with words and all their perfect graphs stored. To get the most probable word from the lexicon the user intended to write, it compares the shapes of the graphs in the shape channel. For this, an amount of N sampling points has to be calculated for every graph. These N points need to be equidistant. Then they have to be normalized in scale and location. This means, that the graphs are all normalized by scaling the largest side of the graph's bounding box to a predetermined length L: 
\begin{equation}
    s = L / max(W,H)
\end{equation}
W and H are the width and height of the graph's bounding box. All points' positions have to be divided by s to get the normalized points' positions. After that, the middle point of every graph have to be set to the point (0,0). Now the distance between the user inputted graph and every word's graph, that is in the lexicon, has to be calculated. To do so, we use the following formula:
\begin{equation}
    x_s = \frac{1}{N}\sum_{i = 1}^{N}\left\lVert u_i - t_i\right\rVert_2
\end{equation}
where $u_i$ is the ith point of the user input graph and $t_i$ the ith point of a word's graph. This is the so-called proportional shape mathcing distance \cite{Kristensson2004SHARK2AL}. The authors stated, that words can have a similar or even same shape as other words. They wrote, that for example on an ATOMIK layout with a lexicon of 20'000 words, there were 1117 pairs of words that have an identical graph.\\
To avoid these so-called confusion pairs, the authors were using a second channel for the location. TODO: LOCATION CHANNEL WITH OR WITHOUT FORMULAS?\\

With these two distances, the most probable word, the user intended to write, can be calculated. To do so, the authors used the following three formulas: TODO: INPUT 3 FORMULAS.\\

The final result c(w) for every word w that met the requirements tells the probability that w is the word, the user intended to write with his/her gesture.\\
The authors say, that the user can draw a graph either on visual guidance from the keyboard (looking for the next letter of a word on the keyboard) or recall from memory. A graph drawn by visual guidance results in a higher location distance score than a graph drawn from memory recall. If a user draws a graph by memory recall the location distance score will be poor and the focus lays more on the shape. Therefore, they suggest a dynamic weighting of the two channels, that is to adjust the weighting of the channels according to the time needed to draw the graph. In general, graphs drawn by memory recall are faster than visual guided ones. Hence, the gesture completion time should tell, how heavy the location channel should be weighted in the final selection. The time to complete a graph for a word obviously depends on its length and complexity. The authors then use Fitts' law (TODO: EITHER FORMULA OR REFERENCE TO IT) to calculate the normative writing time for a graph of a word. They use this result together with the actual graph production time to modify $\delta$ in (TODO: REFERENCE TO FORMULA THEY SUB DELTA).\\
The authors achieved quite satisfactory performance with the two channels, but there still might be conflicting words. To prevent these, the authors suggest to also use language information. For SHARK2 smoothed bigrams are used as the language model. It is then used to rearrange the N-best list of words received before.